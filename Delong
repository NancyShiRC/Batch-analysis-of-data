"""

python Delong.py --intotal_path SRC-table/intotal-cbind.csv --config_path SRC-Delong/delong.json --output_path SRC-Delong/delong.csv

"""
import os
import json
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats

class Color:
    RESET = '\033[0m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    BOLD = '\033[1m'

def delong_roc_test(ground_truth, predictions_one, predictions_two):

    y = np.asarray(ground_truth).flatten()
    score1 = np.asarray(predictions_one).flatten()
    score2 = np.asarray(predictions_two).flatten()

    if len(y) != len(score1) or len(y) != len(score2):
        raise ValueError("输入数组长度必须一致")

    pos_mask = y == 1
    neg_mask = y == 0
    pos_indices = np.where(pos_mask)[0]
    neg_indices = np.where(neg_mask)[0]

    m = len(pos_indices)
    n = len(neg_indices)

    if m == 0 or n == 0:
        raise ValueError("必须同时包含正样本和负样本")

    score1_pos = score1[pos_indices]
    score1_neg = score1[neg_indices]
    score2_pos = score2[pos_indices]
    score2_neg = score2[neg_indices]

    auc1 = _auc(score1_pos, score1_neg, m, n)
    auc2 = _auc(score2_pos, score2_neg, m, n)

    var1, var2, cov = _compute_variances(
        score1_pos, score1_neg, score2_pos, score2_neg,
        m, n, auc1, auc2
    )

    se_squared = var1 + var2 - 2 * cov
    if se_squared < 0:
        se = 0.0
        print(f"{Color.YELLOW}[Warning] 计算得到的方差为负值，这通常意味着两个模型性能极其相似。将标准差视为0。{Color.RESET}")
    else:
        se = np.sqrt(se_squared)

    if se == 0:
        z = 0.0
    else:
        z = (auc1 - auc2) / se
        
    p_value = 2 * (1 - stats.norm.cdf(np.abs(z)))

    return p_value, auc1, auc2

def _auc(score_pos, score_neg, m, n):
    score_matrix = np.subtract.outer(score_pos, score_neg)
    auc = (np.sum(score_matrix > 0) + 0.5 * np.sum(score_matrix == 0)) / (m * n)
    return auc

def _compute_variances(s1p, s1n, s2p, s2n, m, n, auc1, auc2):
    h00 = _h_stat(s1n, s1n)
    h01 = _h_stat(s1n, s2n)
    h10 = _h_stat(s1p, s1p)
    h11 = _h_stat(s1p, s2p)

    var1 = (auc1 * (1 - auc1) + (m - 1) * (h10 - auc1 **2) + (n - 1) * (h00 - auc1** 2)) / (m * n)
    var2 = (auc2 * (1 - auc2) + (m - 1) * (h11 - auc2 **2) + (n - 1) * (h01 - auc2** 2)) / (m * n)

    h0 = _h_stat(s1n, s2n)
    h1 = _h_stat(s1p, s2p)
    cov = (auc1 * auc2 + (m - 1) * (h1 - auc1 * auc2) + (n - 1) * (h0 - auc1 * auc2)) / (m * n)

    return var1, var2, cov

def _h_stat(x, y):
    matrix = np.subtract.outer(x, y)
    h = (np.sum(matrix > 0) + 0.5 * np.sum(matrix == 0)) / (len(x) * len(y))
    return h

def load_config(config_path: str) -> dict:
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        required_keys = ['models', 'target_datasets', 'true_label_col', 'pos_label']
        if not all(key in config for key in required_keys):
            raise ValueError(f"配置文件缺少必要的键: {', '.join(required_keys)}")
        config.setdefault('cmap', 'RdYlBu_r')
        return config
    except Exception as e:
        print(f"{Color.RED}[Error] 加载配置失败: {e}{Color.RESET}")
        raise

def process_comparisons(intotal_df: pd.DataFrame, config: dict):
    models = config['models']
    datasets = config['target_datasets']
    true_label_col = config['true_label_col']

    results = []
    print(f"{Color.BOLD}开始在 {len(datasets)} 个数据集上对 {len(models)} 个模型进行AUC DeLong检验比较...{Color.RESET}")
    
    for dataset in datasets:
        print(f"\n{Color.BLUE}[Info] 正在处理数据集: {dataset}{Color.RESET}")
        df_dataset = intotal_df[intotal_df['set'] == dataset].copy()
        if df_dataset.empty:
            print(f"{Color.YELLOW}[Warning] 数据集 '{dataset}' 中没有找到数据，已跳过。{Color.RESET}")
            continue

        if true_label_col not in df_dataset.columns:
            print(f"{Color.YELLOW}[Warning] 数据集 '{dataset}' 中未找到标签列 '{true_label_col}'，已跳过。{Color.RESET}")
            continue
        
        labels_df = df_dataset[[true_label_col]].dropna()
        if labels_df.empty:
            print(f"{Color.YELLOW}[Warning] 数据集 '{dataset}' 的标签列 '{true_label_col}' 全部为空，已跳过。{Color.RESET}")
            continue
        labels_df = labels_df.astype(int)
        
        if len(labels_df[true_label_col].unique()) < 2:
            print(f"{Color.YELLOW}[Warning] 数据集 '{dataset}' 中只包含一种标签，无法计算AUC，已跳过。{Color.RESET}")
            continue
        
        for i, model_a in enumerate(models):
            for j, model_b in enumerate(models):
                if i == j:
                    continue
                
                if model_a not in df_dataset.columns or model_b not in df_dataset.columns:
                    print(f"{Color.YELLOW}[Warning] 数据集 '{dataset}' 中缺少模型列 '{model_a}' 或 '{model_b}'，已跳过。{Color.RESET}")
                    continue
                
                pred_a_df = df_dataset[[model_a]].dropna()
                pred_b_df = df_dataset[[model_b]].dropna()

                merged_df = pd.merge(labels_df, pred_a_df, left_index=True, right_index=True, how='inner')
                merged_df = pd.merge(merged_df, pred_b_df, left_index=True, right_index=True, how='inner')

                if merged_df.empty:
                    print(f"{Color.YELLOW}[Warning] 模型 '{model_a}' 与 '{model_b}' 无共同的有效预测值和标签，已跳过。{Color.RESET}")
                    continue
                
                if merged_df[model_a].nunique() == 1:
                    print(f"{Color.YELLOW}[Warning] 模型 '{model_a}' 的所有预测值都相同，无法与 '{model_b}' 进行DeLong检验，已跳过。{Color.RESET}")
                    continue
                if merged_df[model_b].nunique() == 1:
                    print(f"{Color.YELLOW}[Warning] 模型 '{model_b}' 的所有预测值都相同，无法与 '{model_a}' 进行DeLong检验，已跳过。{Color.RESET}")
                    continue

                print(f"  - 比较: {model_a} vs {model_b} (有效样本数: {len(merged_df)})")
                try:
                    p_value, auc_a, auc_b = delong_roc_test(
                        merged_df[true_label_col].values, 
                        merged_df[model_a].values, 
                        merged_df[model_b].values
                    )
                    results.append({
                        'Dataset': dataset, 'Model_A': model_a, 'Model_B': model_b,
                        'AUC_Model_A': round(auc_a, 4), 'AUC_Model_B': round(auc_b, 4),
                        'DeLong_p_value': round(p_value, 4), 'Sample_Count': len(merged_df)
                    })
                except Exception as e:
                    print(f"{Color.RED}[Error] 比较 '{model_a}' 与 '{model_b}' 时出错: {e}{Color.RESET}")

    return pd.DataFrame(results)

def _simplify_label(label: str) -> str:
    return label.split('_')[0]

def plot_lower_tri_heatmap(matrix_df, title, output_path, cmap):
    plt.figure(figsize=(8, 6))
    plt.rcParams["font.family"] = ["Arial", "Helvetica", "sans-serif"]
    plt.rcParams['axes.unicode_minus'] = False
    
    mask = np.triu(np.ones_like(matrix_df, dtype=bool), k=1)
    
    ax = sns.heatmap(
        matrix_df, annot=True, fmt='.3f', cmap=cmap, center=0.05,
        square=True, cbar=True, annot_kws={"size": 10}, mask=mask,
        cbar_kws={'label': 'DeLong Test p-value'}
    )
    
    plt.title(title, fontsize=14)
    ax.set_xlabel('Reference Model', fontsize=12)
    ax.set_ylabel('Test Model', fontsize=12)
    
    simplified_labels = [_simplify_label(lbl) for lbl in matrix_df.index]
    ax.set_xticklabels(simplified_labels, rotation=45, ha='right')
    ax.set_yticklabels(simplified_labels, rotation=0)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"{Color.GREEN}[Success] 热图已保存至: {output_path}{Color.RESET}")

def generate_heatmaps(results_df: pd.DataFrame, output_dir: str, cmap: str, models_order: list):
    if results_df.empty:
        print(f"{Color.YELLOW}[Warning] 没有可供绘图的结果数据。{Color.RESET}")
        return
        
    os.makedirs(output_dir, exist_ok=True)
    
    unique_datasets = results_df['Dataset'].unique()
    for dataset in unique_datasets:
        print(f"\n{Color.BLUE}[Info] 正在为数据集 '{dataset}' 生成热图...{Color.RESET}")
        df = results_df[results_df['Dataset'] == dataset].copy()
        
        pval_matrix = df.pivot(index='Model_B', columns='Model_A', values='DeLong_p_value')
        pval_matrix = pval_matrix.reindex(index=models_order, columns=models_order)
        
        np.fill_diagonal(pval_matrix.values, 1.0)
        
        simplified_name = dataset.replace(' ', '_').lower()
        output_path = os.path.join(output_dir, f'delong_p_values_{simplified_name}.pdf')
        
        plot_lower_tri_heatmap(pval_matrix, f'Delong Test p-values ({dataset})', output_path, cmap)

def main():
    parser = argparse.ArgumentParser(description='对指定模型在多个数据集上进行AUC DeLong检验比较。')
    parser.add_argument('--intotal_path', type=str, required=True, help='intotal.csv 文件的路径。')
    parser.add_argument('--config_path', type=str, required=True, help='JSON 配置文件的路径。')
    parser.add_argument('--output_path', type=str, required=True, help='输出结果 CSV 文件的路径。')
    parser.add_argument('--heatmap_dir', type=str, default='heatmaps', help='生成的热图保存目录。')
    args = parser.parse_args()

    try:
        import scipy
    except ImportError:
        print(f"{Color.RED}[Error] 缺少 'scipy' 库。请运行 'pip install scipy' 进行安装。{Color.RESET}")
        return

    try:
        config = load_config(args.config_path)
        intotal_df = pd.read_csv(args.intotal_path)
        
        results_df = process_comparisons(intotal_df, config)

        if not results_df.empty:
            results_df.to_csv(args.output_path, index=False, encoding='utf-8-sig')
            print(f"\n{Color.GREEN}[Success] 比较结果已保存至: {args.output_path}{Color.RESET}")
            
            generate_heatmaps(results_df, args.heatmap_dir, config['cmap'], config['models'])
        else:
            print(f"\n{Color.YELLOW}[Warning] 没有生成任何结果。{Color.RESET}")

    except Exception as e:
        print(f"\n{Color.RED}[Error] 程序执行过程中发生未捕获的错误: {e}{Color.RESET}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
